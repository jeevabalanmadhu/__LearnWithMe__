Decision Tree
-------------

	1.This is one of my favorite algorithm and I use it quite frequently. 

	2.It is a type of supervised learning algorithm that is mostly used for classification problems. 

	3.Surprisingly, it works for both categorical and continuous dependent variables. 

	4.In this algorithm, we split the population into two or more homogeneous sets. 

	5.This is done based on most significant attributes/ independent variables to make as distinct groups 
	  as possible.
-------------------------------------------------------------------------------------------------------------------------------------
DECISION TREE APPLICATIONS
--------------------------

1.Business Management
---------------------

	1.In the past decades, many organizations had created their own databases to enhance their customer 
	  services. 

	2.Decision trees are a possible way to extract useful information from databases and they have already been employed in many 

	  applications in the domain of business and management. 

	3.In particular, decision tree modelling is widely used in customer relationship management and fraud 
	  detection, which are presented in subsections below.

2.Customer Relationship Management
----------------------------------

	1.A frequently used approach to manage customers’ relationships is to investigate how individuals access online services. 

	  Such an investigation is mainly performed by collecting and analyzing individuals’ usage data and then providing 

	  recommendations based on the extracted information. 

-------------------------------------------------------------------------------------------------------------------------------------
Python Code
-----------
#Import Library
#Import other necessary libraries like pandas, numpy...
from sklearn import tree

#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset
# Create tree object 
model = tree.DecisionTreeClassifier(criterion='gini') # for classification, here you can change the algorithm as gini or entropy (information gain) by default it is gini  
# model = tree.DecisionTreeRegressor() for regression

# Train the model using the training sets and check score
model.fit(X, y)
model.score(X, y)

#Predict Output
predicted= model.predict(x_test)
---------------------------------------------------------------------------------------------------------------
Example:
========
from sklearn import tree
import pandas as pd

df=pd.read_csv("C:\\Users\\LENIN\\Desktop\\dataset.csv")
print("\n\nDecision Tree")

model = tree.DecisionTreeClassifier(criterion='gini')

print(model.fit(df[['Age']],df.Salary))
#print(reg.coef_)
#print(reg.intercept_)
print(model.predict(33))

output:
=======
Decision Tree
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
[[-0.10204647]
 [-0.09351406]
 [-0.09628287]
 [-0.08558601]
 [-0.09351406]
 [-0.0614645 ]
 [-0.08558601]
 [-0.07111343]
 [-0.05389518]
 [-0.07111343]
 [-0.07341738]
 [-0.06884718]]
[ 0.19085101  0.0870147   0.12151563 -0.0158391   0.0870147   0.04880455
 -0.0158391  -0.21877519 -0.48432322 -0.21877519 -0.18519125 -0.25227072]
[90000]
---------------------------------------------------------------------------------------------------------------